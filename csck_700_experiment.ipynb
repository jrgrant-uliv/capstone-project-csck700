{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This Jupyter Notebook document contains a series of experiments for machine learning and deep learning-based sequence analysis and sentiment analysis. The experiments include the following:\n",
    "\n",
    "1. Machine-learning based Sequence Analysis using a SVM (Support Vector Machine) model\n",
    "2. Deep-learning-based Sequence Analysis using a LSTM (Long Short-Term Memory) model\n",
    "3. Deep-learning-based Sequence Analysis using a DistilBERT (Transformer) model\n",
    "4. Deep-learning-based Sentiment Analysis using a TCN (Temporal Convolutional Network) model\n",
    "\n",
    "Each experiment focuses on analyzing sequences of events or text data using different models. The goal is to explore the performance and effectiveness of these models in various sequence analysis tasks.\n",
    "\n",
    "The code and explanations for each experiment are provided in the subsequent cells of this Jupyter Notebook document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "\n",
    "1. Environment\n",
    "2. Imports\n",
    "3. Globals\n",
    "4. Utilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and imports\n",
    "\n",
    "This section sets up the environment for the experiment and includes the necessary imports. It consists of the following subsections:\n",
    "\n",
    "Colab specific setup: This subsection contains the necessary installations and code checkout specific to Colab.\n",
    "Global variables and Settings: This subsection defines the global variables and settings used throughout the experiment.\n",
    "Utility Functions: This subsection includes utility functions that are used in the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab Setup\n",
    "\n",
    "To ensure the smooth execution of this Jupyter Notebook document, it is important to perform the necessary Colab specific setup. This setup includes installing required packages, updating the base environment, and cloning the necessary codebase. By following these steps, you can ensure that the notebook runs seamlessly and all dependencies are properly configured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colab Specific installations and Code Checkout\n",
    "\n",
    "The code in this cell checks if the notebook is running on Google Colab. If it is, it installs the condacolab package, updates conda, installs python=3.11, cudatoolkit, tensorflow, and cudnn using conda. It also clones a GitHub repository and copies the codebase and environment_setup directories if they don't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "is_colab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if is_colab:\n",
    "    !pip install condacolab\n",
    "    import condacolab\n",
    "    condacolab.install()\n",
    "    !conda update -n base -c defaults conda\n",
    "    !conda install -y python=3.11 cudatoolkit tensorflow cudnn\n",
    "    !conda clean -ya\n",
    "\n",
    "    if not os.path.exists('codebase'):\n",
    "        !git clone https://github.com/jrgrant-uliv/capstone-project-csck700.git  \n",
    "        !cp -r /content/capstone-project-csck700/codebase ./\n",
    "        !cp -r /content/capstone-project-csck700/environment_setup ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resrouce Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%mkdir -p artefacts/embeddings\n",
    "%mkdir -p application_log_datasets\n",
    "\n",
    "# if CSCK_700_Resources does not exist, download it\n",
    "if not os.path.exists('./CSCK_700_Resources'):\n",
    "    !pip install --upgrade gdown\n",
    "    !gdown https://drive.google.com/drive/folders/1Nsiyt_DseGU1tMTdb08AD65Y6puLIO9B -O ./ --folder\n",
    "    !unzip -oq ./CSCK_700_Resources/HDFS.zip -d ./application_log_datasets/HDFS\n",
    "    !unzip -oq ./CSCK_700_Resources/glove.840B.300d.zip -d ./artefacts/embeddings\n",
    "\n",
    "%cd environment_setup\n",
    "\n",
    "!sh install_dependencies.sh\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the stock stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "from codebase.pipeline.preprocessors.preprocessor import (\n",
    "    BertEventTokenizer,\n",
    "    SequenceVectorizer,\n",
    "    SGTVectorizer,\n",
    ")\n",
    "from codebase.anomaly_detection.models import (\n",
    "    SVMClassifier,\n",
    "    LSTMAttentionClassifier,\n",
    "    TransformerClassifier,\n",
    "    TCNSentimentclassifier,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import warnings\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global varaibles and settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directories\n",
    "output_root = \"./output\"\n",
    "benchmark_results_dir = f\"{output_root}/benchmark_results\"\n",
    "benchmark_results_file = f\"{benchmark_results_dir}/benchmark_results.csv\"\n",
    "plot_dir = f\"{output_root}/plots\"\n",
    "plot_file = f\"{plot_dir}/benchmark_results.png\"\n",
    "model_dir = f\"{output_root}/models\"\n",
    "\n",
    "benchmark_results = []\n",
    "lstm_data = {\n",
    "    \"HDFS\": {\"train\": {\"X\": [], \"y\": []}, \"test\": {\"X\": [], \"y\": []}, \"loaded\": False},\n",
    "    \"Thunderbird\": {\n",
    "        \"train\": {\"X\": [], \"y\": []},\n",
    "        \"test\": {\"X\": [], \"y\": []},\n",
    "        \"loaded\": False,\n",
    "    },\n",
    "}\n",
    "svm_data = {\n",
    "    \"HDFS\": {\"train\": {\"X\": [], \"y\": []}, \"test\": {\"X\": [], \"y\": []}, \"loaded\": False},\n",
    "    \"Thunderbird\": {\n",
    "        \"train\": {\"X\": [], \"y\": []},\n",
    "        \"test\": {\"X\": [], \"y\": []},\n",
    "        \"loaded\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "data_sets = {\n",
    "    \"HDFS\": {\n",
    "        # The benchmark dataset\n",
    "        \"struct_log\": \"./application_log_datasets/HDFS/HDFS.event_traces.csv\",\n",
    "        # The event template file\n",
    "        \"template_file\": \"./application_log_datasets/HDFS/HDFS.log_templates.csv\",\n",
    "    },\n",
    "    \"Thunderbird\": {\n",
    "        # The benchmark dataset\n",
    "        \"struct_log\": \"application_log_datasets/Thunderbird/Thunderbird_20M.log_structured.csv\",\n",
    "        # The event template file\n",
    "        \"template_file\": \"application_log_datasets/Thunderbird/Thunderbird_20M.log_templates.csv\",\n",
    "    },\n",
    "}\n",
    "print(\"Data sets loaded\")\n",
    "# print(data_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure output directories exist\n",
    "if not os.path.exists(output_root):\n",
    "    os.mkdir(output_root)\n",
    "if not os.path.exists(benchmark_results_dir):\n",
    "    os.mkdir(benchmark_results_dir)\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.mkdir(plot_dir)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "\n",
    "def load_event_templates_hdfs(event_templates):\n",
    "    \"\"\"\n",
    "    Load event templates from a CSV file and create a dictionary mapping event IDs to event texts.\n",
    "\n",
    "    Parameters:\n",
    "    event_templates (str): The path to the CSV file containing event templates.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary mapping event IDs to event texts.\n",
    "    \"\"\"\n",
    "    df_event_templates = pd.read_csv(event_templates)\n",
    "    # create an event_id to event_text dictionary\n",
    "    event_id_to_event_text = {}\n",
    "    for index, row in df_event_templates.iterrows():\n",
    "        event_id_to_event_text[row[\"EventId\"]] = row[\"EventTemplate\"]\n",
    "    return event_id_to_event_text\n",
    "\n",
    "\n",
    "def load_data_hdfs(event_traces, event_templates):\n",
    "    \"\"\"\n",
    "    Load data from HDFS and perform feature and label extraction.\n",
    "\n",
    "    Parameters:\n",
    "    event_traces (str): Path to the CSV file containing event traces.\n",
    "    event_templates (str): Path to the CSV file containing event templates.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the feature array (x) and the label array (y).\n",
    "    \"\"\"\n",
    "\n",
    "    df_event_traces = pd.read_csv(event_traces)\n",
    "\n",
    "    # Label: Success = 0, rest = 1\n",
    "    df_event_traces[\"Label\"] = df_event_traces[\"Label\"].apply(\n",
    "        lambda x: 0 if x == \"Success\" else 1\n",
    "    )\n",
    "\n",
    "    # feature and label extraction\n",
    "    x = df_event_traces[\"Features\"].values\n",
    "    y = df_event_traces[\"Label\"].values\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def load_data_thunderbird():\n",
    "    \"\"\"\n",
    "    Load and preprocess the Thunderbird dataset.\n",
    "\n",
    "    Returns:\n",
    "        corpus_df (pandas.DataFrame): Preprocessed Thunderbird dataset.\n",
    "    \"\"\"\n",
    "    tbird_file = data_sets[\"Thunderbird\"][\"struct_log\"]\n",
    "    corpus_df = pd.read_csv(tbird_file)\n",
    "\n",
    "    corpus_df = corpus_df[[\"Label\", \"EventId\", \"EventTemplate\"]]\n",
    "    corpus_df = corpus_df.groupby(\"EventId\").head(5000)\n",
    "    corpus_df.head()\n",
    "\n",
    "    # Update the label column \"-\" is normal, everything else is an anomaly\n",
    "    corpus_df[\"Label\"] = corpus_df[\"Label\"].apply(\n",
    "        lambda x: 0 if x == \"-\" else 1)\n",
    "\n",
    "    # Class counts\n",
    "    print(corpus_df[\"Label\"].value_counts())\n",
    "    return corpus_df\n",
    "\n",
    "\n",
    "def load_data(data_set, model, validation_data=False):\n",
    "    \"\"\"\n",
    "    Load the benchmark dataset.\n",
    "\n",
    "    Args:\n",
    "        data_set (str): The name of the benchmark dataset.\n",
    "        window_size (int): The size of the sliding window.\n",
    "        train_ratio (float): The ratio of the training set to the entire dataset.\n",
    "        split_type (str): The type of the splitting method. It can be 'uniform' or 'sequential'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the training set and test set.\n",
    "    \"\"\"\n",
    "    log_file = data_sets[data_set][\"struct_log\"]\n",
    "    if \"label_file\" in data_sets[data_set]:\n",
    "        label_file = data_sets[data_set][\"label_file\"]\n",
    "    # load templates if in data_sets[data_set]\n",
    "    template_file = None\n",
    "    if \"template_file\" in data_sets[data_set]:\n",
    "        template_file = data_sets[data_set][\"template_file\"]\n",
    "\n",
    "    if data_set == \"HDFS\":\n",
    "        x, y = load_data_hdfs(log_file, template_file)\n",
    "        return x, y\n",
    "    elif data_set == \"Thunderbird\":\n",
    "        corpus = load_data_thunderbird()\n",
    "        return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparaion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hdfs_data(x, y):\n",
    "    \"\"\"\n",
    "    Prepares the HDFS data for training by generating augmented data and combining it with the original data.\n",
    "\n",
    "    Args:\n",
    "        x (numpy.ndarray): The feature data.\n",
    "        y (numpy.ndarray): The label data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The prepared data with augmented samples.\n",
    "\n",
    "    \"\"\"\n",
    "    label_counts = np.bincount(y)\n",
    "    pos_count = label_counts[1]\n",
    "    augmenation_cap = int(pos_count * 0.75)\n",
    "    print(\"Augmentation cap: \", augmenation_cap)\n",
    "    print(\"Label counts: \", label_counts)\n",
    "\n",
    "    new_abnormal = generate_augmented_data(x, augmenation_cap)\n",
    "\n",
    "    original_data_df = pd.DataFrame({\"feature\": x, \"label\": y})\n",
    "    new_abnormal_df = pd.DataFrame({\"feature\": new_abnormal, \"label\": 1})\n",
    "\n",
    "    data_df = pd.concat([original_data_df, new_abnormal_df], ignore_index=True)\n",
    "    # shuffle data_df\n",
    "    data_df = data_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def generate_augmented_data(normal_data, augmentation_sample_size):\n",
    "    \"\"\"\n",
    "    Generate augmented data by applying various anomaly generation techniques to the given normal data.\n",
    "\n",
    "    Parameters:\n",
    "    normal_data (list): A list of strings representing the normal data.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of strings representing the augmented data.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    random_state = 42\n",
    "    random.seed(random_state)\n",
    "\n",
    "    unique_sequence_ids = []\n",
    "    augment_data = []\n",
    "    for x in normal_data:\n",
    "        x = x.replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").split(\",\")\n",
    "        # of the sequence is longer than 5 and has more than 3 unique sequence ids, add it to the augmented data\n",
    "        if len(x) > 5 and len(set(x)) > 3:\n",
    "            augment_data.append(x)\n",
    "            if len(augment_data) >= augmentation_sample_size:\n",
    "                break\n",
    "        for y in x:\n",
    "            if y not in unique_sequence_ids:\n",
    "                unique_sequence_ids.append(y)\n",
    "    print(\"Number of unique sequence ids: \", len(unique_sequence_ids))\n",
    "    print(\"Size of sample for augmentation: \", len(augment_data))\n",
    "    print(\"Sampled data: \", augment_data[0])\n",
    "    sampled_data = random.sample(augment_data, int(len(augment_data) * 0.6))\n",
    "    reversed_sequences = []\n",
    "    for x in sampled_data:\n",
    "        x.reverse()\n",
    "        reversed_sequences.append(x)\n",
    "    print(\"Sampled reversed sequences: \", reversed_sequences[:5])\n",
    "    # randomly select another 20% of the normal dataset and generate shuffled sequences as anomalies\n",
    "    sampled_data = random.sample(augment_data, int(len(augment_data) * 0.3))\n",
    "    shuffled_sequences = []\n",
    "    for x in sampled_data:\n",
    "        random.shuffle(x)\n",
    "        shuffled_sequences.append(x)\n",
    "    print(\"Sampled shuffled sequences: \", shuffled_sequences[:5])\n",
    "\n",
    "    # randomly select another 20% of the normal dataset and randomly insert sequence ids from unique_sequence_ids as anomalies\n",
    "    sampled_data = random.sample(augment_data, int(len(augment_data) * 0.2))\n",
    "    inserted_sequences = []\n",
    "    for x in sampled_data:\n",
    "        # insert a random sequence id from unique_sequence_ids at a random point\n",
    "        random_index = random.randint(0, len(x) - 1)\n",
    "        # insert up to 10 sequence ids\n",
    "        insert_count = random.randint(1, 10)\n",
    "        for i in range(insert_count):\n",
    "            random_sequence_id = random.choice(unique_sequence_ids)\n",
    "            x.insert(random_index, random_sequence_id)\n",
    "        inserted_sequences.append(x)\n",
    "    print(\"Sampled inserted sequences: \", inserted_sequences[:5])\n",
    "    # combine all the augmented data\n",
    "    augmented_data = reversed_sequences + shuffled_sequences + inserted_sequences\n",
    "    print(\"Number of augmented sequences: \", len(augmented_data))\n",
    "    print(\"Sampled augmented data: \", augmented_data[:5])\n",
    "    # reassemble as a string representation of a list\n",
    "    new_abnormal = []\n",
    "    for lst in augment_data:\n",
    "        lst = \",\".join(lst)\n",
    "        lst = f\"[{lst}]\"\n",
    "        new_abnormal.append(lst)\n",
    "    return new_abnormal\n",
    "\n",
    "\n",
    "def process_text_corpus(text_corpus_df, word_split=None):\n",
    "    \"\"\"\n",
    "    Process the text corpus dataframe by performing various transformations.\n",
    "\n",
    "    Args:\n",
    "        text_corpus_df (pandas.DataFrame): The input text corpus dataframe.\n",
    "        word_split (dict, optional): A dictionary containing words to split and their replacements.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The processed text corpus dataframe.\n",
    "    \"\"\"\n",
    "    split_words = word_split is not None\n",
    "    lm = WordNetLemmatizer()\n",
    "    english_stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "    # Train Corpus\n",
    "    print(\"Process Training Corpus\")\n",
    "    text_corpus_df[\"EventTemplate\"] = text_corpus_df[\"EventTemplate\"].apply(\n",
    "        lambda x: x.lower()\n",
    "    )\n",
    "    text_corpus_df[\"EventTemplate\"] = text_corpus_df[\"EventTemplate\"].replace(\n",
    "        {\"<.*?>\": \" \"}, regex=True\n",
    "    )\n",
    "    text_corpus_df[\"EventTemplate\"] = text_corpus_df[\"EventTemplate\"].replace(\n",
    "        {\"[^a-zA-Z]\": \" \"}, regex=True\n",
    "    )\n",
    "    text_corpus_df[\"EventTemplate\"] = text_corpus_df[\"EventTemplate\"].replace(\n",
    "        {\"\\s+\": \" \"}, regex=True\n",
    "    )\n",
    "    if split_words:\n",
    "        for word in word_split:\n",
    "            replace = \" \".join(word_split[word]).lower()\n",
    "            print(replace)\n",
    "            text_corpus_df[\"EventTemplate\"] = text_corpus_df[\n",
    "                \"EventTemplate\"\n",
    "            ].str.replace(word, replace)\n",
    "\n",
    "    text_corpus_df[\"EventTemplate\"] = text_corpus_df[\"EventTemplate\"].apply(\n",
    "        lambda x: [\n",
    "            lm.lemmatize(word)\n",
    "            for word in x.split(\" \")\n",
    "            if not word in english_stops and word != \"\"\n",
    "        ]\n",
    "    )\n",
    "    # remove '' from list in column X\n",
    "    text_corpus_df[\"EventTemplate\"] = text_corpus_df[\"EventTemplate\"].apply(\n",
    "        lambda x: [word for word in x if word != \"\"]\n",
    "    )\n",
    "    # convert list in column X to string\n",
    "    text_corpus_df[\"EventTemplate\"] = text_corpus_df[\"EventTemplate\"].apply(\n",
    "        lambda x: \" \".join(x)\n",
    "    )\n",
    "\n",
    "    return text_corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(max_len, d_model):\n",
    "    \"\"\"\n",
    "    Generate positional encoding for transformer models.\n",
    "\n",
    "    Parameters:\n",
    "    - max_len (int): Maximum sequence length.\n",
    "    - d_model (int): Dimensionality of the model.\n",
    "\n",
    "    Returns:\n",
    "    - pos_enc (np.ndarray): Positional encoding of shape (1, max_len, d_model).\n",
    "    \"\"\"\n",
    "    position = np.arange(0, max_len)[:, np.newaxis]\n",
    "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "    pos_enc = np.zeros((max_len, d_model))\n",
    "    pos_enc[:, 0::2] = np.sin(position * div_term)\n",
    "    pos_enc[:, 1::2] = np.cos(position * div_term)\n",
    "    pos_enc = pos_enc[np.newaxis, ...]\n",
    "    return pos_enc.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_deployment(classifier, vectorizer):\n",
    "    \"\"\"\n",
    "    Saves the trained classifier model and associated artifacts for deployment.\n",
    "\n",
    "    Args:\n",
    "        classifier (Classifier): The trained classifier object.\n",
    "        vectorizer (Vectorizer): The vectorizer object used for feature extraction.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    classifier.save_model_file()\n",
    "    model_artefact_dir = classifier.model_artefact_dir\n",
    "    if vectorizer is not None:\n",
    "        tokenizer_file = os.path.join(model_artefact_dir, \"tokenizer.pkl\")\n",
    "        vectorizer.save_tokenizer(tokenizer_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    clf,\n",
    "    _model,\n",
    "    _data_set,\n",
    "    accuracies,\n",
    "    precisions,\n",
    "    recalls,\n",
    "    fscores,\n",
    "    aucs,\n",
    "    conf_matrices,\n",
    "    roc_curves,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a machine learning model.\n",
    "\n",
    "    Args:\n",
    "        clf: The classifier model.\n",
    "        _model: The name of the model.\n",
    "        _data_set: The name of the dataset.\n",
    "        accuracies: List of accuracy scores.\n",
    "        precisions: List of precision scores.\n",
    "        recalls: List of recall scores.\n",
    "        fscores: List of F1 scores.\n",
    "        aucs: List of AUC scores.\n",
    "        conf_matrices: List of confusion matrices.\n",
    "        roc_curves: List of ROC curves.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    conf_matrix = np.mean(conf_matrices, axis=0).astype(np.int32)\n",
    "    tn = conf_matrix[0][0]\n",
    "    fp = conf_matrix[0][1]\n",
    "    tp = conf_matrix[1][1]\n",
    "    fn = conf_matrix[1][0]\n",
    "    pos = tp + fn\n",
    "    neg = fp + tn\n",
    "    accuracy = np.mean(accuracies)\n",
    "    precision = np.mean(precisions)\n",
    "    recall = np.mean(recalls)\n",
    "    f1 = np.mean(fscores)\n",
    "    auc = np.mean(aucs)\n",
    "    TPR = tp / pos\n",
    "    FPR = fp / neg\n",
    "    TNR = tn / neg\n",
    "    FNR = fn / pos\n",
    "    CSR = (tp + tn) / (pos + neg)\n",
    "    CFR = (fp + fn) / (pos + neg)\n",
    "    MTTD_Impact1 = CFR / CSR\n",
    "    MTTD_Impact2 = CSR / CFR\n",
    "\n",
    "\n",
    "\n",
    "    save_conf_matrix(clf, conf_matrix)\n",
    "    plot_confusion_matrix(clf, conf_matrix)\n",
    "    plot_roc(clf, roc_curves, aucs)\n",
    "\n",
    "    save_benchmark_results(\n",
    "        _model,\n",
    "        _data_set,\n",
    "        accuracy,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1,\n",
    "        auc,\n",
    "        conf_matrix,\n",
    "        tp,\n",
    "        fp,\n",
    "        tn,\n",
    "        fn,\n",
    "        pos,\n",
    "        neg,\n",
    "        TPR,\n",
    "        FPR,\n",
    "        TNR,\n",
    "        FNR,\n",
    "        CSR,\n",
    "        CFR,\n",
    "        MTTD_Impact1,\n",
    "        MTTD_Impact2,\n",
    "    )\n",
    "\n",
    "    plot_metrics()\n",
    "\n",
    "\n",
    "def evaluate_svm(clf, _model, _data_set, y_pred, y_true, accuracy):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a Support Vector Machine (SVM) classifier.\n",
    "\n",
    "    Parameters:\n",
    "    - clf: The trained SVM classifier.\n",
    "    - _model: The name or identifier of the model being evaluated.\n",
    "    - _data_set: The name or identifier of the dataset being evaluated.\n",
    "    - y_pred: The predicted labels.\n",
    "    - y_true: The true labels.\n",
    "    - accuracy: The accuracy scores for each prediction.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.mean(accuracy)\n",
    "\n",
    "    # Calculate precision, recall, and F-score\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    tp = conf_matrix[0][0]\n",
    "    fp = conf_matrix[0][1]\n",
    "    tn = conf_matrix[1][1]\n",
    "    fn = conf_matrix[1][0]\n",
    "    pos = tp + fn\n",
    "    neg = fp + tn\n",
    "    TPR = tp / pos\n",
    "    FPR = fp / neg\n",
    "    TNR = tn / neg\n",
    "    FNR = fn / pos\n",
    "    CSR = (tp + tn) / (pos + neg)\n",
    "    CFR = (fp + fn) / (pos + neg)\n",
    "    MTTD_Impact1 = CFR / CSR\n",
    "    MTTD_Impact2 = CFR / (1 - CSR)\n",
    "\n",
    "\n",
    "    save_conf_matrix(clf, conf_matrix)\n",
    "    plot_confusion_matrix(clf, conf_matrix)\n",
    "    roc = roc_curve(y_true, y_pred)\n",
    "    plot_roc(clf, [roc], [auc])\n",
    "\n",
    "    save_benchmark_results(\n",
    "        _model,\n",
    "        _data_set,\n",
    "        accuracy,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1,\n",
    "        auc,\n",
    "        conf_matrix,\n",
    "        tp,\n",
    "        fp,\n",
    "        tn,\n",
    "        fn,\n",
    "        pos,\n",
    "        neg,\n",
    "        TPR,\n",
    "        FPR,\n",
    "        TNR,\n",
    "        FNR,\n",
    "        CSR,\n",
    "        CFR,\n",
    "        MTTD_Impact1,\n",
    "        MTTD_Impact2,\n",
    "    )\n",
    "\n",
    "    plot_metrics()\n",
    "\n",
    "\n",
    "def save_conf_matrix(clf, conf_matrix):\n",
    "    \"\"\"\n",
    "    Save the confusion matrix to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        clf (object): The classifier object.\n",
    "        conf_matrix (array-like): The confusion matrix.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model_conf_matrix_file = os.path.join(\n",
    "        clf.model_artefact_dir, \"confusion_matrix.csv\"\n",
    "    )\n",
    "    conf_matrix_df = pd.DataFrame(\n",
    "        conf_matrix,\n",
    "        index=[\"Actual Negative\", \"Actual Positive\"],\n",
    "        columns=[\"Predicted Negative\", \"Predicted Positive\"],\n",
    "    )\n",
    "    conf_matrix_df.to_csv(model_conf_matrix_file)\n",
    "\n",
    "\n",
    "def save_benchmark_results(\n",
    "    model,\n",
    "    dataset,\n",
    "    accuracy,\n",
    "    precision,\n",
    "    recall,\n",
    "    f1,\n",
    "    auc,\n",
    "    conf_matrix,\n",
    "    tp,\n",
    "    fp,\n",
    "    tn,\n",
    "    fn,\n",
    "    pos,\n",
    "    neg,\n",
    "    TPR,\n",
    "    FPR,\n",
    "    TNR,\n",
    "    FNR,\n",
    "    CSR,\n",
    "    CFR,\n",
    "    MTTD_Impact1,\n",
    "    MTTD_Impact2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save benchmark results to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        model (str): The name of the model.\n",
    "        dataset (str): The name of the dataset.\n",
    "        accuracy (float): The accuracy score.\n",
    "        precision (float): The precision score.\n",
    "        recall (float): The recall score.\n",
    "        f1 (float): The F1 score.\n",
    "        auc (float): The AUC score.\n",
    "        conf_matrix (array-like): The confusion matrix.\n",
    "        tp (int): The number of true positives.\n",
    "        fp (int): The number of false positives.\n",
    "        tn (int): The number of true negatives.\n",
    "        fn (int): The number of false negatives.\n",
    "        pos (int): The number of positive instances.\n",
    "        neg (int): The number of negative instances.\n",
    "        mttd_impact1 (float): The impact score 1.\n",
    "        mttd_impact2 (float): The impact score 2.\n",
    "    \"\"\"\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F1: \", f1)\n",
    "    print(\"AUC: \", auc)\n",
    "    print(\"Confusion Matrix: \", conf_matrix)\n",
    "\n",
    "    # add metrics to extended_benchmark_results\n",
    "    benchmark_results.append(\n",
    "        [\n",
    "            model,\n",
    "            dataset,\n",
    "            accuracy,\n",
    "            precision,\n",
    "            recall,\n",
    "            f1,\n",
    "            auc,\n",
    "            pos,\n",
    "            neg,\n",
    "            tp,\n",
    "            fp,\n",
    "            fn,\n",
    "            tn,\n",
    "            TPR,\n",
    "            FPR,\n",
    "            TNR,\n",
    "            FNR,\n",
    "            CSR,\n",
    "            CFR,\n",
    "            MTTD_Impact1,\n",
    "            MTTD_Impact2,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(benchmark_results_dir):\n",
    "        os.makedirs(benchmark_results_dir)\n",
    "    df = pd.DataFrame(\n",
    "        benchmark_results,\n",
    "        columns=[\n",
    "            \"model\",\n",
    "            \"dataset\",\n",
    "            \"accuracy\",\n",
    "            \"precision\",\n",
    "            \"recall\",\n",
    "            \"f1\",\n",
    "            \"auc\",\n",
    "            \"pos\",\n",
    "            \"neg\",\n",
    "            \"tp\",\n",
    "            \"fp\",\n",
    "            \"fn\",\n",
    "            \"tn\",\n",
    "            \"tpr\",\n",
    "            \"fpr\",\n",
    "            \"tnr\",\n",
    "            \"fnr\",\n",
    "            \"csr\",\n",
    "            \"cfr\",\n",
    "            \"mttd_impact1\",\n",
    "            \"mttd_impact2\",\n",
    "        ],\n",
    "    )\n",
    "    df.to_csv(benchmark_results_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and process Glove Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Downloads and processes the GloVe embeddings if necessary.\n",
    "\n",
    "Args:\n",
    "    None\n",
    "\n",
    "Returns:\n",
    "    None\n",
    "\"\"\"\n",
    "\n",
    "path = './artefacts/embeddings/'\n",
    "nb_file_path=path+'glove.840B.300d.txt'\n",
    "pkl_file = f'{path}/glove.840B.300d.pkl'\n",
    "\n",
    "force_process_glove = False\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    force_process_glove = True\n",
    "\n",
    "if not os.path.exists(pkl_file):\n",
    "    force_process_glove = True\n",
    "\n",
    "if force_process_glove:\n",
    "    if not os.path.exists(nb_file_path):\n",
    "        !wget http://nlp.stanford.edu/data/glove.840B.300d.zip -P {path}\n",
    "        !unzip {path}/glove.840B.300d.zip -d {path}\n",
    "        !rm {path}/glove.840B.300d.zip\n",
    "\n",
    "    df = pd.read_csv(nb_file_path, sep=\" \", quoting=3, header=None, index_col=0)\n",
    "    embeddings_index = {key: val.values for key, val in df.T.items()}\n",
    "    #\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "    import pickle\n",
    "    pkl_file = f'{path}/glove.840B.300d.pkl'\n",
    "    with open(pkl_file, 'wb') as fp:\n",
    "        pickle.dump(embeddings_index, fp)\n",
    "else:\n",
    "    reload_embedding_index = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics():\n",
    "    \"\"\"\n",
    "    Plots the metrics (accuracy, precision, recall, and F1 score) for different models and datasets.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(\n",
    "        benchmark_results,\n",
    "        columns=[\n",
    "            \"model\",\n",
    "            \"dataset\",\n",
    "            \"accuracy\",\n",
    "            \"precision\",\n",
    "            \"recall\",\n",
    "            \"f1\",\n",
    "            \"auc\",\n",
    "            \"pos\",\n",
    "            \"neg\",\n",
    "            \"tp\",\n",
    "            \"fp\",\n",
    "            \"fn\",\n",
    "            \"tn\",\n",
    "            \"tpr\",\n",
    "            \"fpr\",\n",
    "            \"tnr\",\n",
    "            \"fnr\",\n",
    "            \"csr\",\n",
    "            \"cfr\",\n",
    "            \"mttd_impact1\",\n",
    "            \"mttd_impact2\",\n",
    "        ],\n",
    "    )\n",
    "    # Define a color palette for models\n",
    "    model_palette = sns.color_palette(\"Set1\", n_colors=len(df['model'].unique()))\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.barplot(x=\"model\", y=\"accuracy\", hue=\"dataset\", data=df, palette=model_palette)\n",
    "    plt.title(\"Accuracy\")\n",
    "\n",
    "    # Precision Plot\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.barplot(x=\"model\", y=\"precision\", hue=\"dataset\", data=df, palette=model_palette)\n",
    "    plt.title(\"Precision\")\n",
    "\n",
    "    # Recall Plot\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.barplot(x=\"model\", y=\"recall\", hue=\"dataset\", data=df, palette=model_palette)\n",
    "    plt.title(\"Recall\")\n",
    "\n",
    "    # F1 Score Plot\n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.barplot(x=\"model\", y=\"f1\", hue=\"dataset\", data=df, palette=model_palette)\n",
    "    plt.title(\"F1 Score\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(plot_file)\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(clf, roc_curves, auc_scores):\n",
    "    \"\"\"\n",
    "    Plots the ROC curves for a classifier.\n",
    "\n",
    "    Args:\n",
    "        clf (Classifier): The classifier object.\n",
    "        roc_curves (list): List of ROC curves.\n",
    "        auc_score (float): The AUC score.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model_name = clf.model_name\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    split = 1\n",
    "    for roc in roc_curves:\n",
    "        fpr = roc[0]\n",
    "        tpr = roc[1]\n",
    "        auc = auc_scores[split - 1]\n",
    "        plt.plot(\n",
    "            fpr, tpr, label=f\"Cross-validation split {split} - AUC = {auc:.2f}\"\n",
    "        )\n",
    "        split += 1\n",
    "\n",
    "    plt.title(f\"ROC Curves {model_name}\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(clf.model_artefact_dir, \"roc_curves.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(clf, conf_matrix):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix using a heatmap.\n",
    "\n",
    "    Parameters:\n",
    "    - clf: The classifier object.\n",
    "    - conf_matrix: The confusion matrix to be plotted.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(\n",
    "        conf_matrix,\n",
    "        annot=True,\n",
    "        fmt=\"g\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"True\", \"False\"],\n",
    "        yticklabels=[\"True\", \"False\"],\n",
    "    )\n",
    "    plt.title(\"Confusion Matrix - \" + clf.model_name)\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.savefig(os.path.join(clf.model_artefact_dir, \"confusion_matrix.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads HDFS event sequences, prepares the data, and optionally reduces the data.\n",
    "\"\"\"\n",
    "\n",
    "reduce_data = False\n",
    "print(\"Loading HDFS Event Sequences\")\n",
    "x, y = load_data(\"HDFS\", \"SVM\")\n",
    "hdfs_data_df = prepare_hdfs_data(x, y)\n",
    "\n",
    "if reduce_data:\n",
    "    print(\"Reducing HDFS Event Sequences\")\n",
    "    hdfs_data_df = hdfs_data_df.drop(\n",
    "        hdfs_data_df[hdfs_data_df.label == 0].sample(\n",
    "            frac=0.5, random_state=42).index\n",
    "    )\n",
    "    hdfs_data_df = hdfs_data_df.drop(\n",
    "        hdfs_data_df[hdfs_data_df.label == 1].sample(\n",
    "            frac=0.5, random_state=42).index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(\n",
    "    tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Running in Colab: \", is_colab)\n",
    "print(\"Running in Docker: \", is_docker)\n",
    "print(\"Running locally: \", is_local)\n",
    "print(\"Has GPU: \", has_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Run all the cells above this one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - SVM\n",
    "\n",
    "Statistical Analysis using an SVM (Support Vector Machine) model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code performs an experiment using the HDFS dataset and SVM model.\n",
    "It loads the data, prepares it, and splits it into train and test sets.\n",
    "It then applies TF-IDF vectorization to the data and calculates class weights.\n",
    "Finally, it prints the shapes of the train and test data, the normal to anomaly ratio,\n",
    "the counts of normal and anomaly classes, and the class weights.\n",
    "\"\"\"\n",
    "\n",
    "_data_set = \"HDFS\"\n",
    "_model = \"SVM\"\n",
    "print(_data_set, _model)\n",
    "\n",
    "if hdfs_data_df is None:\n",
    "    x, y = load_data(_data_set, _model)\n",
    "    hdfs_data_df = prepare_hdfs_data(x, y)\n",
    "\n",
    "x = hdfs_data_df[\"feature\"].tolist()\n",
    "y = hdfs_data_df[\"label\"].tolist()\n",
    "y = np.array(y)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = SequenceVectorizer(mode=\"tfidf\")\n",
    "vectorizer.fit(x)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42\n",
    ")\n",
    "train_data = vectorizer.transform(train_data)\n",
    "test_data = vectorizer.transform(test_data)\n",
    "\n",
    "class_counts = np.unique(train_labels, return_counts=True)[1]\n",
    "ratio = class_counts[0] / class_counts[1]\n",
    "class_weights = {0: 1, 1: ratio}\n",
    "\n",
    "print(\"Train data shape: \", train_data.shape)\n",
    "print(\"Test data shape: \", test_data.shape)\n",
    "print(\"Normal to anomaly ratio: \", ratio)\n",
    "print(\"Normal: \", class_counts[0])\n",
    "print(\"Anomaly: \", class_counts[1])\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lstm_units = 8\n",
    "num_epochs = 10\n",
    "num_splits = 5\n",
    "prediction_threshold = 0.9\n",
    "model_name = \"SVMClassifier_HDFS\"\n",
    "\n",
    "classifier = SVMClassifier(model_name=model_name, class_weight=class_weights)\n",
    "svc_model = classifier.build_model()\n",
    "\n",
    "# Perform cross-validation and get predictions\n",
    "y_pred = cross_val_predict(svc_model, train_data, train_labels, cv=5)\n",
    "# Calculate accuracy\n",
    "accuracy = cross_val_score(\n",
    "    svc_model, train_data, train_labels, cv=5, scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "evaluate_svm(classifier, _model, _data_set, y_pred, train_labels, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_svm(classifier, _model, _data_set, y_pred, train_labels, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1. Sequence Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code performs an experiment using the HDFS dataset and LSTM model.\n",
    "It loads the data, prepares it, and splits it into train and test sets.\n",
    "It then vectorizes the data, calculates class weights, and prints relevant information.\n",
    "\"\"\"\n",
    "\n",
    "_data_set = \"HDFS\"\n",
    "_model = \"LSTM\"\n",
    "print(_data_set, _model)\n",
    "\n",
    "sequence_length = 128\n",
    "feature_dim = 1\n",
    "\n",
    "if hdfs_data_df is None:\n",
    "    x, y = load_data(_data_set, _model)\n",
    "    hdfs_data_df = prepare_hdfs_data(x, y)\n",
    "\n",
    "\n",
    "x = hdfs_data_df[\"feature\"].tolist()\n",
    "y = hdfs_data_df[\"label\"].tolist()\n",
    "y = np.array(y)\n",
    "\n",
    "vectorizer = SequenceVectorizer(num_words=sequence_length)\n",
    "vectorizer.fit(x)\n",
    "train_data = vectorizer.transform(x)\n",
    "train_labels = y\n",
    "\n",
    "vocab_size = len(vectorizer.tokenizer.word_index) + 1\n",
    "train_data = train_data.reshape(\n",
    "    train_data.shape[0], sequence_length, feature_dim)\n",
    "\n",
    "class_counts = np.unique(train_labels, return_counts=True)[1]\n",
    "ratio = class_counts[0] / class_counts[1]\n",
    "class_weights = {0: 1, 1: ratio}\n",
    "\n",
    "print(\"Train data shape: \", train_data.shape)\n",
    "print(\"Normal to anomaly ratio: \", ratio)\n",
    "print(\"Normal: \", class_counts[0])\n",
    "print(\"Anomaly: \", class_counts[1])\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lstm_units = 8\n",
    "num_epochs = 10\n",
    "num_splits = 5\n",
    "prediction_threshold = 0.9\n",
    "model_name = \"LSTMAttentionClassifier_HDFS_SequenceMatrix\"\n",
    "\n",
    "classifier = LSTMAttentionClassifier(\n",
    "    model_name,\n",
    "    feature_dim,\n",
    "    sequence_length,\n",
    "    vocab_size,\n",
    "    lstm_units=lstm_units,\n",
    ")\n",
    "\n",
    "(\n",
    "    accuracies,\n",
    "    precisions,\n",
    "    recalls,\n",
    "    fscores,\n",
    "    aucs,\n",
    "    conf_matrices,\n",
    "    roc_curves,\n",
    ") = classifier.cross_validate(\n",
    "    train_data, train_labels, num_splits, num_epochs, prediction_threshold\n",
    ")\n",
    "\n",
    "evaluate_model(\n",
    "    classifier,\n",
    "    _model,\n",
    "    _data_set,\n",
    "    accuracies,\n",
    "    precisions,\n",
    "    recalls,\n",
    "    fscores,\n",
    "    aucs,\n",
    "    conf_matrices,\n",
    "    roc_curves,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r ./artefacts/models/LSTMAttentionClassifier_HDFS_SequenceMatrix ./output/benchmark_results/benchmark_results.csv LSTMAttentionClassifier_HDFS_SequenceMatrix.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2. Sequence Embeddings usint Sequence Graph Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code performs an experiment using the HDFS dataset and LSTM model.\n",
    "It loads the data, prepares it, and splits it into train and test sets.\n",
    "It then applies a sequence-to-graph transformation using SGTVectorizer.\n",
    "Finally, it calculates class weights and prints various information about the data.\n",
    "\"\"\"\n",
    "_data_set = \"HDFS\"\n",
    "_model = \"LSTM\"\n",
    "print(_data_set, _model)\n",
    "\n",
    "sequence_length = 32\n",
    "feature_dim = 1\n",
    "\n",
    "# Load and prepare the HDFS data\n",
    "if hdfs_data_df is None:\n",
    "    x, y = load_data(_data_set, _model)\n",
    "    hdfs_data_df = prepare_hdfs_data(x, y)\n",
    "\n",
    "x = hdfs_data_df[\"feature\"].tolist()\n",
    "for i in range(len(x)):\n",
    "    x[i] = x[i].replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \" \").split(\" \")\n",
    "\n",
    "y = hdfs_data_df[\"label\"].tolist()\n",
    "y = np.array(y)\n",
    "\n",
    "# Prepare train data\n",
    "train_data_df = pd.DataFrame({\"sequence\": x, \"label\": y})\n",
    "train_data_df = train_data_df.reset_index()\n",
    "train_data_df = train_data_df.rename(columns={\"index\": \"id\"})\n",
    "train_labels = train_data_df[\"label\"].tolist()\n",
    "train_data_df.drop(columns=[\"label\"], inplace=True)\n",
    "\n",
    "# Apply sequence-to-graph transformation using SGTVectorizer\n",
    "vectorizer = SGTVectorizer(num_dims=sequence_length)\n",
    "train_data = vectorizer.fit_transform(train_data_df)\n",
    "\n",
    "# Convert train and test data to arrays\n",
    "train_data_arr = []\n",
    "for i in train_data:\n",
    "    i = i.tolist()\n",
    "    train_data_arr.append(i)\n",
    "train_data.shape\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = np.unique(train_labels, return_counts=True)[1]\n",
    "ratio = class_counts[0] / class_counts[1]\n",
    "class_weights = {0: 1, 1: ratio}\n",
    "\n",
    "# Print information about the data\n",
    "print(\"Train data shape: \", train_data.shape)\n",
    "print(\"Normal to anomaly ratio: \", ratio)\n",
    "print(\"Normal: \", class_counts[0])\n",
    "print(\"Anomaly: \", class_counts[1])\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 500\n",
    "batch_size = 128\n",
    "lstm_units = 8\n",
    "num_epochs = 10\n",
    "num_splits = 5\n",
    "prediction_threshold = 0.9\n",
    "model_name = \"LSTMAttentionClassifier_HDFS_SGT\"\n",
    "\n",
    "classifier = LSTMAttentionClassifier(\n",
    "    model_name,\n",
    "    feature_dim,\n",
    "    sequence_length,\n",
    "    vocab_size,\n",
    "    lstm_units=lstm_units,\n",
    ")\n",
    "\n",
    "(\n",
    "    accuracies,\n",
    "    precisions,\n",
    "    recalls,\n",
    "    fscores,\n",
    "    aucs,\n",
    "    conf_matrices,\n",
    "    roc_curves,\n",
    ") = classifier.cross_validate(\n",
    "    train_data, train_labels, num_splits, num_epochs, prediction_threshold\n",
    ")\n",
    "\n",
    "evaluate_model(\n",
    "    classifier,\n",
    "    _model,\n",
    "    _data_set,\n",
    "    accuracies,\n",
    "    precisions,\n",
    "    recalls,\n",
    "    fscores,\n",
    "    aucs,\n",
    "    conf_matrices,\n",
    "    roc_curves,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preaparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code performs data preprocessing and prepares the data for training a Transformer model on the HDFS dataset.\n",
    "It loads the data, prepares the features and labels, splits the data into train, test, and validation sets,\n",
    "and calculates class weights for imbalanced data.\n",
    "\"\"\"\n",
    "\n",
    "_data_set = \"HDFS\"\n",
    "_model = \"Transformer\"\n",
    "print(_data_set, _model)\n",
    "batch_size = 32\n",
    "\n",
    "if hdfs_data_df is None:\n",
    "    x, y = load_data(_data_set, _model)\n",
    "    hdfs_data_df = prepare_hdfs_data(x, y)\n",
    "\n",
    "reduce_data_df = hdfs_data_df.drop(\n",
    "    hdfs_data_df[hdfs_data_df.label == 0].sample(\n",
    "        frac=0.75, random_state=42).index\n",
    ")\n",
    "\n",
    "x = reduce_data_df[\"feature\"].tolist()\n",
    "y = reduce_data_df[\"label\"].tolist()\n",
    "y = np.array(y)\n",
    "\n",
    "max_len = max([len(i) for i in x])\n",
    "\n",
    "model_type = \"distilbert-base-uncased\"\n",
    "preprocessor = BertEventTokenizer(\n",
    "    model_type=model_type, batch_size=batch_size, max_length=128\n",
    ")\n",
    "train_tokens, train_masks = preprocessor.transform(x)\n",
    "vocab_size = preprocessor.vocab_size\n",
    "seq_len = preprocessor.max_length\n",
    "train_data = [train_tokens, train_masks]\n",
    "train_labels = y\n",
    "\n",
    "class_counts = np.unique(train_labels, return_counts=True)[1]\n",
    "ratio = class_counts[0] / class_counts[1]\n",
    "class_weights = {0: 1, 1: ratio}\n",
    "\n",
    "print(\"Train data shape: \", train_data[0].shape)\n",
    "print(\"Normal to anomaly ratio: \", ratio)\n",
    "print(\"Normal: \", class_counts[0])\n",
    "print(\"Anomaly: \", class_counts[1])\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 640\n",
    "batch_size = 16\n",
    "if is_colab:\n",
    "    batch_size = 64\n",
    "num_epochs = 10\n",
    "num_splits = 5\n",
    "prediction_threshold = 0.9\n",
    "model_name = \"Transformer_classifier_HDFS\"\n",
    "\n",
    "classifier = TransformerClassifier(\n",
    "    \"Transformer_classifier_HDFS\", 1, seq_len, vocab_size, model_type=model_type\n",
    ")\n",
    "\n",
    "(\n",
    "    accuracies,\n",
    "    precisions,\n",
    "    recalls,\n",
    "    fscores,\n",
    "    aucs,\n",
    "    conf_matrices,\n",
    "    roc_curves,\n",
    ") = classifier.cross_validate(\n",
    "    train_data, train_labels, num_splits, num_epochs, prediction_threshold\n",
    ")\n",
    "\n",
    "evaluate_model(\n",
    "    classifier,\n",
    "    _model,\n",
    "    _data_set,\n",
    "    accuracies,\n",
    "    precisions,\n",
    "    recalls,\n",
    "    fscores,\n",
    "    aucs,\n",
    "    conf_matrices,\n",
    "    roc_curves,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 - TCN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code performs a series of data preprocessing steps and prepares the data for training a machine learning model.\n",
    "It loads a dataset, processes the text corpus, applies feature string mapping, splits the data into training and testing sets,\n",
    "performs sequence vectorization, prepares word embeddings, calculates class weights, and prints information about the data.\n",
    "\"\"\"\n",
    "_data_set = \"HDFS\"\n",
    "_model = \"TCN\"\n",
    "print(_data_set, _model)\n",
    "batch_size = 32\n",
    "\n",
    "hdfs_event_templates = data_sets[\"HDFS\"][\"template_file\"]\n",
    "m = load_event_templates_hdfs(hdfs_event_templates)\n",
    "\n",
    "# load dictionary m into a dataframe, key as column 'EventId', value as column 'EventTemplate'\n",
    "event_templates_df = pd.DataFrame(\n",
    "    m.items(), columns=[\"EventId\", \"EventTemplate\"])\n",
    "\n",
    "word_split = {\n",
    "    \"namesystem\": [\"name\", \"system\"],\n",
    "    \"allocateblock\": [\"allocate\", \"block\"],\n",
    "    \"packetresponder\": [\"packet\", \"responder\"],\n",
    "    \"addstoredblock\": [\"add\", \"stored\", \"block\"],\n",
    "    \"invalidset\": [\"invalid\", \"set\"],\n",
    "    \"ioexception\": [\"input\", \"exception\"],\n",
    "    \"writeblock\": [\"write\", \"block\"],\n",
    "    \"blockinfo\": [\"block\", \"info\"],\n",
    "    \"volumemap\": [\"volume\", \"map\"],\n",
    "    \"receiveblock\": [\"receive\", \"block\"],\n",
    "    \"socketchannel\": [\"socket\", \"channel\"],\n",
    "    \"interruptedioexception\": [\"interrupted\", \"input\", \"exception\"],\n",
    "    \"interruptedinput\": [\"interrupted\", \"input\"],\n",
    "    \"eofexception\": [\"file\", \"exception\"],\n",
    "    \"sockettimeoutexception\": [\"socket\", \"timeout\", \"exception\"],\n",
    "    \"pendingreplicationmonitor\": [\"pending\", \"replication\", \"monitor\"],\n",
    "    \"neededreplications\": [\"needed\", \"replications\"],\n",
    "}\n",
    "\n",
    "event_templates_df = process_text_corpus(event_templates_df, word_split)\n",
    "\n",
    "m = dict(zip(event_templates_df[\"EventId\"],\n",
    "         event_templates_df[\"EventTemplate\"]))\n",
    "\n",
    "x, y = load_data(_data_set, _model)\n",
    "\n",
    "print(\"Preparing data for training...\")\n",
    "hdfs_corpus_df = pd.DataFrame({\"feature\": x, \"label\": y})\n",
    "hdfs_corpus_df = hdfs_corpus_df.drop(\n",
    "    hdfs_corpus_df[hdfs_corpus_df.label == 0].sample(\n",
    "        frac=0.75, random_state=42).index\n",
    ")\n",
    "hdfs_corpus_df[\"feature_str\"] = (\n",
    "    hdfs_corpus_df[\"feature\"].str.replace(\n",
    "        \"[\", \"\").str.replace(\"]\", \"\").str.split(\",\")\n",
    ")\n",
    "print(hdfs_corpus_df.head())\n",
    "\n",
    "print(\"Apply feature string mapping\")\n",
    "hdfs_corpus_df[\"feature_str\"] = hdfs_corpus_df[\"feature_str\"].apply(\n",
    "    lambda x: [m[str(i)] for i in x]\n",
    ")\n",
    "print(hdfs_corpus_df.head())\n",
    "\n",
    "hdfs_corpus_df[\"feature_str\"] = hdfs_corpus_df[\"feature_str\"].apply(\n",
    "    lambda x: \" \".join(x)\n",
    ")\n",
    "hdfs_corpus_df[\"feature_str\"] = hdfs_corpus_df[\"feature_str\"].apply(\n",
    "    lambda x: x.split(\" \")\n",
    ")\n",
    "train_data = hdfs_corpus_df[\"feature_str\"]\n",
    "train_labels = np.asarray(hdfs_corpus_df[\"label\"].tolist())\n",
    "\n",
    "sequence_length = 128\n",
    "vectorizer = SequenceVectorizer(num_words=sequence_length)\n",
    "vectorizer.fit(train_data)\n",
    "train_data = vectorizer.transform(train_data)\n",
    "vectorizer.tokenizer.word_counts\n",
    "vocab_size = len(vectorizer.tokenizer.word_index) + 1\n",
    "\n",
    "word_index = vectorizer.tokenizer.word_index\n",
    "EMBEDDING_DIM = 64\n",
    "MAX_NB_WORDS = 2000\n",
    "\n",
    "if reload_embedding_index:\n",
    "    path = \"./artefacts/embeddings/\"\n",
    "    pkl_file = f\"{path}/glove.840B.300d.pkl\"\n",
    "    # load embeddings_index from file\n",
    "    with open(pkl_file, \"rb\") as fp:\n",
    "        embeddings_index = pickle.load(fp)\n",
    "\n",
    "print(\"Preparing embedding matrix\")\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index)) + 1\n",
    "word_embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "dead_words = []\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        # trim the embedding vector to the embedding dimension\n",
    "        if len(embedding_vector) > EMBEDDING_DIM:\n",
    "            embedding_vector = embedding_vector[:EMBEDDING_DIM]\n",
    "        word_embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        dead_words.append(word)\n",
    "print(dead_words)\n",
    "\n",
    "print(\"Null word embeddings: %d\" %\n",
    "      np.sum(np.sum(word_embedding_matrix, axis=1) == 0))\n",
    "\n",
    "# find words in embedding matrix that nave no embeddings\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    if np.sum(word_embedding_matrix[i]) == 0:\n",
    "        print(word)\n",
    "\n",
    "positional_embedding_matrix = positional_encoding(\n",
    "    len(word_index) + 1, EMBEDDING_DIM)\n",
    "positional_embedding_matrix = positional_embedding_matrix.reshape(\n",
    "    positional_embedding_matrix.shape[1], positional_embedding_matrix.shape[2]\n",
    ")\n",
    "\n",
    "class_counts = np.unique(train_labels, return_counts=True)[1]\n",
    "ratio = class_counts[0] / class_counts[1]\n",
    "class_weights = {0: 1, 1: ratio}\n",
    "\n",
    "print(\"Train data shape: \", train_data.shape)\n",
    "# print(\"Test data shape: \", test_data.shape)\n",
    "print(\"Normal to anomaly ratio: \", ratio)\n",
    "print(\"Normal: \", class_counts[0])\n",
    "print(\"Anomaly: \", class_counts[1])\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_input_dim = 300\n",
    "input_size = sequence_length\n",
    "input_dim = EMBEDDING_DIM\n",
    "tcn_filters = 32\n",
    "tcn_kernel_size = 3\n",
    "dropout_rate = 0.25\n",
    "input_dim = vocab_size\n",
    "num_epochs = 10\n",
    "num_splits = 5\n",
    "prediction_threshold = 0.9\n",
    "\n",
    "model_name = \"TCNSentimentClassifier_HDFS\"\n",
    "\n",
    "classifier = TCNSentimentclassifier(\n",
    "    model_name,\n",
    "    input_size,\n",
    "    input_dim,\n",
    "    positional_embedding_matrix,\n",
    "    word_embedding_matrix,\n",
    "    embedding_output_dim=EMBEDDING_DIM,\n",
    "    tcn_units=128,\n",
    "    prediction_threshold=0.9,\n",
    ")\n",
    "\n",
    "\n",
    "(\n",
    "    accuracies,\n",
    "    precisions,\n",
    "    recalls,\n",
    "    fscores,\n",
    "    aucs,\n",
    "    conf_matrices,\n",
    "    roc_curves,\n",
    ") = classifier.cross_validate(\n",
    "    train_data, train_labels, num_splits, num_epochs, prediction_threshold\n",
    ")\n",
    "\n",
    "evaluate_model(\n",
    "    classifier,\n",
    "    _model,\n",
    "    _data_set,\n",
    "    accuracies,\n",
    "    precisions,\n",
    "    recalls,\n",
    "    fscores,\n",
    "    aucs,\n",
    "    conf_matrices,\n",
    "    roc_curves,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: HDFS and THunderbird combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hdfs_corpus_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Thunderbird Event corpus\")\n",
    "thunderbird_corpus_df = load_data(\"Thunderbird\", \"TCN\")\n",
    "thunderbird_corpus_df = thunderbird_corpus_df.drop(\n",
    "    thunderbird_corpus_df[thunderbird_corpus_df.Label == 0]\n",
    "    .sample(frac=0.95, random_state=42)\n",
    "    .index\n",
    ")\n",
    "thunderbird_corpus_df = process_text_corpus(thunderbird_corpus_df)\n",
    "print(\"Reducing the normal class in Thunderbird corpus\")\n",
    "\n",
    "# if hdfs_corpus_df contains 'feature_str'\n",
    "if \"feature_str\" in hdfs_corpus_df.columns:\n",
    "    # drop the 'feature' column from the hdf corpus\n",
    "    hdfs_corpus_df = hdfs_corpus_df.drop(columns=[\"feature\"])\n",
    "    # rename the 'feature_str' column to 'feature'\n",
    "    hdfs_corpus_df = hdfs_corpus_df.rename(columns={\"feature_str\": \"feature\"})\n",
    "\n",
    "# rename the 'EventTemplate' column to 'feature' on t_bird_corpus_df\n",
    "t_bird_corpus_df = thunderbird_corpus_df.rename(\n",
    "    columns={\"EventTemplate\": \"feature\"})\n",
    "# rename the 'Label' column to 'label' on t_bird_corpus_df\n",
    "t_bird_corpus_df = t_bird_corpus_df.rename(columns={\"Label\": \"label\"})\n",
    "# combine the two datasets\n",
    "combined_df = pd.concat([t_bird_corpus_df, hdfs_corpus_df])\n",
    "print(combined_df[\"label\"].value_counts())\n",
    "combined_df = combined_df.sample(frac=1, random_state=42)\n",
    "print(combined_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hdfs_corpus_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = combined_df[\"feature\"].tolist()\n",
    "train_df, test_df = train_test_split(\n",
    "    combined_df, test_size=0.3, random_state=42)\n",
    "train_data = train_df[\"feature\"]\n",
    "train_labels = np.asarray(train_df[\"label\"].tolist())\n",
    "test_data = test_df[\"feature\"]\n",
    "test_labels = np.asarray(test_df[\"label\"].tolist())\n",
    "train_data = pd.Series(train_data)\n",
    "test_data = pd.Series(test_data)\n",
    "\n",
    "vectorizer = SequenceVectorizer(num_words=sequence_length)\n",
    "vectorizer.fit(x)\n",
    "train_data = vectorizer.transform(train_data)\n",
    "test_data = vectorizer.transform(test_data)\n",
    "train_data = train_data.reshape(train_data.shape[0], train_data.shape[1], 1)\n",
    "test_data = test_data.reshape(test_data.shape[0], test_data.shape[1], 1)\n",
    "vocab_size = len(vectorizer.tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = vectorizer.tokenizer.word_index\n",
    "EMBEDDING_DIM = 128\n",
    "MAX_NB_WORDS = 2000\n",
    "\n",
    "if reload_embedding_index:\n",
    "    path = \"./artefacts/embeddings/\"\n",
    "    pkl_file = f\"{path}/glove.840B.300d.pkl\"\n",
    "    # load embeddings_index from file\n",
    "    with open(pkl_file, \"rb\") as fp:\n",
    "        embeddings_index = pickle.load(fp)\n",
    "\n",
    "print(\"Preparing embedding matrix\")\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index)) + 1\n",
    "word_embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "dead_words = []\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        # trim the embedding vector to the embedding dimension\n",
    "        if len(embedding_vector) > EMBEDDING_DIM:\n",
    "            embedding_vector = embedding_vector[:EMBEDDING_DIM]\n",
    "        word_embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        dead_words.append(word)\n",
    "print(dead_words)\n",
    "\n",
    "print(\"Null word embeddings: %d\" %\n",
    "      np.sum(np.sum(word_embedding_matrix, axis=1) == 0))\n",
    "\n",
    "# find words in embedding matrix that nave no embeddings\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    if np.sum(word_embedding_matrix[i]) == 0:\n",
    "        print(word)\n",
    "\n",
    "# how frequently is that word used in our corpus?\n",
    "train_df[\"feature\"].apply(lambda x: \" \".join(x)).str.contains(\"<OOV>\").sum()\n",
    "\n",
    "positional_embedding_matrix = positional_encoding(\n",
    "    len(word_index) + 1, EMBEDDING_DIM)\n",
    "positional_embedding_matrix = positional_embedding_matrix.reshape(\n",
    "    positional_embedding_matrix.shape[1], positional_embedding_matrix.shape[2]\n",
    ")\n",
    "\n",
    "# embedding_input_dim = 300\n",
    "input_dim = EMBEDDING_DIM\n",
    "tcn_filters = 32\n",
    "tcn_kernel_size = 3\n",
    "dropout_rate = 0.25\n",
    "input_dim = vocab_size\n",
    "num_epochs = 42\n",
    "patience = 5\n",
    "\n",
    "model_name = \"TCNSentimentClassifier_Combined\"\n",
    "classifier = TCNSentimentclassifier(\n",
    "    model_name,\n",
    "    input_size,\n",
    "    input_dim,\n",
    "    positional_embedding_matrix,\n",
    "    word_embedding_matrix,\n",
    "    embedding_output_dim=EMBEDDING_DIM,\n",
    "    tcn_units=128,\n",
    "    prediction_threshold=0.9,\n",
    ")\n",
    "history = classifier.train(\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    patience=patience,\n",
    ")\n",
    "\n",
    "save_model_deployment(classifier, vectorizer)\n",
    "\n",
    "# evaluate LSTM classifier\n",
    "eval_model(\n",
    "    benchmark_results, \"Combined\", _data_set, [], [], test_data, test_labels, classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = np.asarray(\n",
    "    [\n",
    "        \"failed to connect\",\n",
    "        \"record updated sucessfully\",\n",
    "        \"block updated\",\n",
    "        \"session opened on database\",\n",
    "        \"bad block found\",\n",
    "    ]\n",
    ")\n",
    "y = np.asarray([0])\n",
    "\n",
    "for i in range(len(text)):\n",
    "    print(text[i])\n",
    "    test = vectorizer.fit_transform([text[i]])\n",
    "    print(test.shape)\n",
    "    test = test.reshape(test.shape[0], test.shape[1], 1)\n",
    "    print(test.shape)\n",
    "    a = classifier.model.predict(test)\n",
    "    print(a[0], (a[0] > 0.5).astype(\"int32\"))\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_corpus_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
